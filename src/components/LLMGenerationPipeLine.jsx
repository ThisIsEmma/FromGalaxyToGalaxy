import React from 'react';
import '../styles/LLMGenerationPipeLine.css';


const LLMGenerationPipeLine = () => {
  return (
    <div className="context-page">
      <h1>ðŸ§  From Character to Prediction: How Language Models Work</h1>

      <section className="context-section">
        <h2>âœ… Full Process: From Character to Prediction</h2>

        <h3>â‘  Text Encoding: string â†’ integer</h3>
        <p>
          The input string (e.g., "hello") is encoded into a sequence of integers:
          <br />
          'h' â†’ 43, 'e' â†’ 30, ...
          <br />
          This is called tokenization. It maps each character to a unique number.
        </p>

        <h3>â‘¡ Lookup: integer â†’ vector (embedding)</h3>
        <p>
          Each integer ID (like 43) is mapped to a vector using <code>nn.Embedding</code>:
          <br />
          Embedding(43) â†’ [0.1, -0.2, ..., 0.9]
        </p>

        <h3>â‘¢ Model Computation: vector â†’ logits (prediction scores)</h3>
        <p>
          These vectors go through the model and produce a set of logits:
          <br />
          logits = [2.3, -1.1, 0.5, ..., 3.2]
          <br />
          Each logit is the model's score for each possible next token.
        </p>

        <h3>â‘£ Softmax: logits â†’ probabilities</h3>
        <p>
          The logits are turned into actual probabilities:
          <br />
          probs = softmax(logits) â†’ [0.6, 0.2, 0.1, ..., 0.01]
        </p>

        <h3>â‘¤ Sampling: probs â†’ next token</h3>
        <p>
          The model randomly selects the next token using <code>torch.multinomial</code>:
          <br />
          id_next = torch.multinomial(probs, 1) â†’ 0
        </p>

        <h3>â‘¥ Decoding: integer â†’ character</h3>
        <p>
          The token is converted back into a character:
          <br />
          itos[0] â†’ ' '
        </p>

        <h3>ðŸ“Œ Summary</h3>
        <p>
          A language model: transforms characters to vectors â†’ predicts probabilities for the next token â†’ samples to generate text.
        </p>
      </section>
    </div>
  );
};

export default LLMGenerationPipeLine;